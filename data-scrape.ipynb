{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c4fc31c-5ba0-49dd-aa4c-3d610ad0fa71",
   "metadata": {},
   "source": [
    "## OpenAlex API - Fetching Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53a9cad9-4a42-4e2b-b9eb-a4caffcae30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "# debug\n",
    "import pdb\n",
    "from loguru import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b286401-da04-4e03-9833-47ca303413fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. OpenAlex API Docs: https://docs.openalex.org/api\n",
    "# 0. OpenAlex API Tutorials: https://github.com/ourresearch/openalex-api-tutorials\n",
    "# 1. additional request packages: https://stackoverflow.com/a/18579484\n",
    "# 2. custom tqdm: https://stackoverflow.com/questions/45808140/using-tqdm-progress-bar-in-a-while-loop \n",
    "# 3. loguru tutorial: https://medium.com/analytics-vidhya/a-quick-guide-to-using-loguru-4042dc5437a5\n",
    "# 3.1 multiple loggers: https://github.com/Delgan/loguru/issues/333"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e1372b3-a1fc-40e0-a14c-1d3a729b550c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example work: https://api.openalex.org/works?filter=publication_year:2021&per-page=2\n",
    "\n",
    "## Preprocessing Utils\n",
    "def get_id(url):\n",
    "    return url.split('https://openalex.org/')[1]\n",
    "\n",
    "def get_url(id_):\n",
    "    return f'https://openalex.org/{id_}'\n",
    "\n",
    "def get_cited_by_url(work_id_):\n",
    "    return f'https://api.openalex.org/works?filter=cites:{work_id_}'\n",
    "\n",
    "\n",
    "def int_author_position(pos):\n",
    "    if pos.lower() == 'first':\n",
    "        return 1\n",
    "    elif pos.lower() == 'middle':\n",
    "        return 2\n",
    "    elif pos.lower() == 'last':\n",
    "        return 3\n",
    "    \n",
    "def parse_authorships(authorships):\n",
    "    return [\n",
    "        [\n",
    "            get_id(auth['author']['id']), \n",
    "            [get_id(inst['id']) if inst['id'] else None for inst in auth['institutions']]\n",
    "        ]\n",
    "        for auth in sorted(authorships, key=lambda x: int_author_position(x['author_position']))\n",
    "    ]\n",
    "\n",
    "def parse_concepts(concepts):\n",
    "    top_k = 5\n",
    "    return [\n",
    "        [\n",
    "            get_id(con['id']), \n",
    "            con['score']\n",
    "        ]\n",
    "        for con in sorted(concepts, key=lambda x: x['score'], reverse=True)\n",
    "    ][:top_k]\n",
    "    \n",
    "def parse_abstract(abstract_inverted_index):\n",
    "    max_len = max([j for _, i in abstract_inverted_index.items() for j in i]) + 1\n",
    "    abstract = ['' for _ in range(max_len)]\n",
    "    for key, value in abstract_inverted_index.items():\n",
    "        for idx in value:\n",
    "            abstract[idx] = key\n",
    "    return ' '.join(abstract)\n",
    "\n",
    "def parse_counts_by_year(counts_by_year):\n",
    "    return [\n",
    "        [\n",
    "            count['year'],\n",
    "            count['cited_by_count']\n",
    "        ]\n",
    "        for count in counts_by_year\n",
    "    ]\n",
    "\n",
    "def preprocess(works):\n",
    "    processed_works = []\n",
    "    for work in works:\n",
    "        if work['id'] is None:\n",
    "            continue\n",
    "        if work['host_venue']['id'] is None:\n",
    "            continue\n",
    "        if None in [\n",
    "            auth['author']['id'] \n",
    "            for auth in work['authorships']\n",
    "        ]:\n",
    "            continue\n",
    "        if None in [\n",
    "            inst['id'] \n",
    "            for auth in work['authorships'] \n",
    "                for inst in auth['institutions']\n",
    "        ]:\n",
    "            continue\n",
    "        if None in [\n",
    "            con['id'] \n",
    "            for con in work['concepts']\n",
    "        ]:\n",
    "            continue\n",
    "\n",
    "        processed_works.append({\n",
    "            'id': get_id(work['id']),\n",
    "            'doi': work['doi'],\n",
    "            'title': work['title'],\n",
    "            'type': work['type'],\n",
    "            'publication_date': work['publication_date'],\n",
    "            'host_venue': get_id(work['host_venue']['id']),\n",
    "            'open_access_is_oa': work['open_access']['is_oa'],\n",
    "            'open_access_oa_status': work['open_access']['oa_status'],\n",
    "            'authorships': parse_authorships(work['authorships']),\n",
    "            'cited_by_count': work['cited_by_count'],\n",
    "            'concepts': parse_concepts(work['concepts']),\n",
    "            'referenced_works': [get_id(ref) for ref in work['referenced_works']],\n",
    "            'abstract': parse_abstract(work['abstract_inverted_index']),\n",
    "            'counts_by_year': parse_counts_by_year(work['counts_by_year']),\n",
    "        })\n",
    "    return processed_works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3cea04f-56c1-4a6e-b600-2cf061a0d6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dry run: {'count': 4185273, 'db_response_time_ms': 120, 'page': 1, 'per_page': 25}\n"
     ]
    }
   ],
   "source": [
    "## Init Params\n",
    "\n",
    "LOG_PATH = './log.v3.txt'\n",
    "DATA_PATH = './data.v3.txt'\n",
    "MAX_RESULTS = 100000\n",
    "PER_PAGE = 200\n",
    "\n",
    "INIT_PAGE, INIT_CURSOR = 0, '*'\n",
    "# INIT_PAGE, INIT_CURSOR = 298, 'Ils5MCwgJ2h0dHBzOi8vb3BlbmFsZXgub3JnL1cyNjI0MTg2MjY4J10i'\n",
    "\n",
    "DATA_URL = 'https://api.openalex.org/works?'\\\n",
    "                'filter=from_publication_date:2016-01-01,'\\\n",
    "                'to_publication_date:2020-12-31,'\\\n",
    "                'has_abstract:true,'\\\n",
    "                'has_references:true,'\\\n",
    "                'is_paratext:false,'\\\n",
    "                'is_retracted:false,'\\\n",
    "                'concepts.id:C41008148'\n",
    "\n",
    "email = 'armaan.1997@cs.iitr.ac.in'\n",
    "\n",
    "expected_results = requests.get(DATA_URL).json()['meta']\n",
    "print ('dry run:', expected_results)\n",
    "results_remain = PER_PAGE * INIT_PAGE <= min(MAX_RESULTS, expected_results['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "171f6a39-d01f-4a29-84e3-171973cea626",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–         | 100200/4185273 [09:06<6:11:29, 183.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last log: \n",
      "  - page: 501, \n",
      "  - cursor: Ils2NiwgJ2h0dHBzOi8vb3BlbmFsZXgub3JnL1cyOTQ0Mjk3NTUyJ10i, \n",
      "  - hit_url: https://api.openalex.org/works?filter=from_publication_date:2016-01-01,to_publication_date:2020-12-31,has_abstract:true,has_references:true,is_paratext:false,is_retracted:false,concepts.id:C41008148&per_page=200&cursor=Ils2NiwgJ2h0dHBzOi8vb3BlbmFsZXgub3JnL1cyOTAxODQ5NTcxJ10i\n",
      "Logs saved to file: ./log.v3.txt\n",
      "Data saved to file: ./data.v3.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Scraping Code\n",
    "\n",
    "logger.remove()\n",
    "logger.add(LOG_PATH, backtrace=True, diagnose=True, catch=True, \n",
    "           filter=lambda record: record[\"level\"].name == \"INFO\")\n",
    "logger.add(DATA_PATH, rotation='500 MB', \n",
    "           filter=lambda record: record[\"level\"].name == \"SUCCESS\",\n",
    "           format=\"{message}\")\n",
    "\n",
    "headers = {\n",
    "    \"Accept\": \"application/json\",\n",
    "    \"User-Agent\": f\"mailto:{email}\"\n",
    "}\n",
    "\n",
    "\n",
    "with tqdm(total=expected_results['count']) as pbar:\n",
    "    pbar.update(PER_PAGE*INIT_PAGE)\n",
    "    page = INIT_PAGE\n",
    "    cursor = INIT_CURSOR\n",
    "    while results_remain:\n",
    "        hit_url = DATA_URL + f'&per_page={PER_PAGE}&cursor={cursor}'\n",
    "        response = requests.get(hit_url, headers=headers) # scrape data, API call\n",
    "        \n",
    "        try:\n",
    "            assert (response.status_code == 200), 'oops'\n",
    "            works = response.json()['results'] # parse data\n",
    "            page += 1\n",
    "            \n",
    "            processed_works = preprocess(works)\n",
    "            logger.success (processed_works) # data logging\n",
    "            logger.info ('page: {}, works:{}, processed works: {}, hit url: {}'\n",
    "                         .format(page, len(works), len(processed_works), hit_url)) # scrape logging\n",
    "            pbar.update(len(works))\n",
    "            \n",
    "            cursor = response.json()['meta']['next_cursor'] # parse next pointer to data\n",
    "            results_remain = PER_PAGE * page <= min(MAX_RESULTS, expected_results['count'])\n",
    "        except Exception as err:\n",
    "            print (f\"Got {response.json()} from OpenAlex\")\n",
    "            print (f\"Unexpected {err}, {type(err)}\")\n",
    "            break\n",
    "            \n",
    "\n",
    "print (f'Last log: \\n  - page: {page}, \\n  - cursor: {cursor}, \\n  - hit_url: {hit_url}')\n",
    "print (f'Logs saved to file: {LOG_PATH}')\n",
    "print (f'Data saved to file: {DATA_PATH}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b94730-7830-487b-928a-3a801efbf284",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be4079d-a3be-4376-b89c-61fd9cec4dfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf9b5a6-7f95-4536-8b8d-23a26b898fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## to resume, check line of log file for {cursor, page, hit_url}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
